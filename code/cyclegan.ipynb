{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data path\n",
    "dat_dir = ''\n",
    "\n",
    "\n",
    "# data config\n",
    "img_h = 256\n",
    "img_b = 256\n",
    "channels = 3\n",
    "\n",
    "\n",
    "# configs\n",
    "epochs = 0\n",
    "n_epochs = 5\n",
    "batch_size = 1\n",
    "lr = 0.0002\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "decay_epoch = 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBLock(nn.Module):\n",
    "\n",
    "    def __init__(self , in_f):\n",
    "        super(ResidualBLock , self).__init__()\n",
    "\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1) , \n",
    "            nn.Conv2d(in_f , in_f , 3) , \n",
    "            nn.InstanceNorm2d(in_f) , \n",
    "            # inplace  = True for memory efficiency\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ReflectionPad2d(1) , \n",
    "            nn.Conv2d(in_f , in_f , 3), \n",
    "            nn.InstanceNorm2d(in_f)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self , x):\n",
    "        return x + self.block(x)\n",
    "    \n",
    "\n",
    "\n",
    "class GeneratorResNet(nn.Module):\n",
    "\n",
    "    def __init__(self , input_shape , num_res_block):\n",
    "\n",
    "        super(GeneratorResNet , self).__init__()\n",
    "\n",
    "\n",
    "        channels = input_shape[0]\n",
    "\n",
    "        out_f = 64\n",
    "\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(channels),\n",
    "            nn.Conv2d(channels , out_f , 7),\n",
    "            nn.InstanceNorm2d(out_f),   #helps to learn features which are invariate to brightness and contrast\n",
    "            nn.ReLU(inplace=True)\n",
    "            \n",
    "        ]\n",
    "\n",
    "        in_f = out_f\n",
    "\n",
    "\n",
    "        # downsampling\n",
    "\n",
    "        for _ in range(2):\n",
    "\n",
    "            out_f *= 2\n",
    "            model += [\n",
    "                nn.Conv2d(in_f , out_f , 3,stride=2 , padding=1), \n",
    "                nn.InstanceNorm2d(out_f),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "\n",
    "            in_f = out_f\n",
    "\n",
    "\n",
    "        # Residual BLock\n",
    "        for _ in range(num_res_block):\n",
    "            model += [ResidualBLock(out_f)]\n",
    "\n",
    "\n",
    "        # upsampling\n",
    "\n",
    "        for _ in range(2):\n",
    "\n",
    "            out_f //= 2\n",
    "            model += [\n",
    "                nn.Upsample(scale_factor=2), # --> this means width * 2 , height * 2\n",
    "                nn.Conv2d(in_f, out_f , 3 , stride=1 , padding= 1),\n",
    "                nn.ReLU(inplace=True)\n",
    "\n",
    "            ]\n",
    "\n",
    "            in_f = out_f\n",
    "        # output lapyer\n",
    "\n",
    "\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(channels) , \n",
    "            nn.Conv2d(out_f  , channels , 7) ,\n",
    "            nn.Tanh()\n",
    "            ]\n",
    "        \n",
    "        # unpacking\n",
    "\n",
    "        self.model = nn.Sequential(*model)\n",
    "\n",
    "    \n",
    "\n",
    "    def forward(self , x):\n",
    "        return self.model(x)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self , inp_size):\n",
    "\n",
    "        super(Discriminator , self).__init__()\n",
    "\n",
    "\n",
    "        channels , height , width = inp_size\n",
    "\n",
    "\n",
    "        self.output_shape = (1,  height//2**4 , width // 2**4)\n",
    "\n",
    "\n",
    "        def discriminator_bloc(in_filters , out_filters , normalize = True):\n",
    "            layers = [\n",
    "                nn.Conv2d(in_filters , out_filters , 4 , stride=2 , padding=1)]\n",
    "            \n",
    "            if normalize:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "\n",
    "            layers.append(nn.LeakyReLU(0.2 , inplace=True))\n",
    "\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *discriminator_bloc(channels , 64 , normalize=False) ,\n",
    "            *discriminator_bloc(64 , 128) ,\n",
    "            *discriminator_bloc(128 , 256) , \n",
    "            *discriminator_bloc(256 , 512),\n",
    "            nn.ZeroPad2d((1,0,1,0)),\n",
    "            nn.Conv2d(512 , 1 ,4 ,padding=1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self  , img):\n",
    "         return self.model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOSS FUNCTION\n",
    "\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_cycle = torch.nn.L1Loss()\n",
    "criterion_identity = torch.nn.L1Loss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (channels , img_h , img_b)\n",
    "\n",
    "n_residual_blocks = 9\n",
    "\n",
    "G_AB = GeneratorResNet(input_shape=input_shape , num_res_block=n_residual_blocks)\n",
    "G_BA = GeneratorResNet(input_shape=input_shape , num_res_block=n_residual_blocks)\n",
    "\n",
    "D_A = Discriminator(inp_size=input_shape)\n",
    "D_B = Discriminator(inp_size=input_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "\n",
    "if cuda:\n",
    "    G_AB = G_AB.cuda()\n",
    "    G_BA = G_BA.cuda()\n",
    "    D_A = D_A.cuda()\n",
    "    D_B = D_B.cuda()\n",
    "    \n",
    "    criterion_GAN.cuda()\n",
    "    criterion_cycle.cuda()\n",
    "    criterion_identity.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('Conv') != -1:\n",
    "        torch.nn.init.normal(m.weight.data ,0.0 , 0.02)\n",
    "\n",
    "        if hasattr(m , 'bias') and m.bias  is not None:\n",
    "            torch.nn.init.constant(m.bias.data , 0.0)\n",
    "\n",
    "        elif classname.find('BatchNorm2d') != -1:\n",
    "            torch.nn.init.normal(m.weight.data , 1.0 , 0.02)\n",
    "            torch.nn.init.constant(m.bias.data , 0.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_668764/2943737239.py:6: UserWarning: nn.init.normal is now deprecated in favor of nn.init.normal_.\n",
      "  torch.nn.init.normal(m.weight.data ,0.0 , 0.02)\n",
      "/tmp/ipykernel_668764/2943737239.py:9: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  torch.nn.init.constant(m.bias.data , 0.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Discriminator(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (3): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (6): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    (9): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
       "    (11): ZeroPad2d((1, 0, 1, 0))\n",
       "    (12): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), padding=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_AB.apply(weights_init_normal)\n",
    "G_BA.apply(weights_init_normal)\n",
    "D_A.apply(weights_init_normal)\n",
    "D_B.apply(weights_init_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temp_weights_init_normal(m):\n",
    "    classname =  m.__class__.__name__\n",
    "    print(classname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "InstanceNorm2d\n",
      "Sequential\n",
      "ResidualBLock\n",
      "Upsample\n",
      "Conv2d\n",
      "ReLU\n",
      "Upsample\n",
      "Conv2d\n",
      "ReLU\n",
      "ReflectionPad2d\n",
      "Conv2d\n",
      "Tanh\n",
      "Sequential\n",
      "GeneratorResNet\n"
     ]
    }
   ],
   "source": [
    "G_AB.apply(temp_weights_init_normal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "optim_G = torch.optim.Adam(itertools.chain(G_AB.parameters() , G_BA.parameters()) , lr=lr , betas=(b1,b2))\n",
    "\n",
    "optim_D_A = torch.optim.Adam(D_A.parameters() , lr=lr , betas=(b1,b2))\n",
    "\n",
    "optim_D_B = torch.optim.Adam(D_B.parameters() , lr=lr , betas=(b1,b2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LambdaLR:\n",
    "\n",
    "    def __init__(self , n_epochs  , offset , decay_start_epoch):\n",
    "        assert (n_epochs - decay_start_epoch) > 0 , \"Decay myst start before the treaining session ends\"\n",
    "\n",
    "        self.n_epochs = n_epochs\n",
    "        self.offset = offset\n",
    "        self.decay_start_epoch = decay_start_epoch\n",
    "\n",
    "\n",
    "    def step(self , epoch):\n",
    "        return 1.0 - max(0 , epoch+ self.offset - self.decay_start_epoch)/(self.n_epochs - self.decay_start_epoch)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler_G = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_G,\n",
    "    lr_lambda=LambdaLR(n_epochs, epochs, decay_epoch).step\n",
    ")\n",
    "\n",
    "lr_scheduler_D_A = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_D_A,\n",
    "    lr_lambda=LambdaLR(n_epochs, epochs, decay_epoch).step\n",
    ")\n",
    "lr_scheduler_D_B = torch.optim.lr_scheduler.LambdaLR(\n",
    "    optim_D_B,\n",
    "    lr_lambda=LambdaLR(n_epochs, epochs, decay_epoch).step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transforms_ = [\n",
    "    transforms.Resize(int(img_h*1.12), Image.BICUBIC),\n",
    "    transforms.RandomCrop((img_h, img_b)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_rgb(image):\n",
    "    rgb_image = Image.new(\"RGB\", image.size)\n",
    "    rgb_image.paste(image)\n",
    "    return rgb_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (525429090.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[19], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    def __init__(self , root ,transforms= None , unaligned = False , mode = 'train'):\u001b[0m\n\u001b[0m                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self , root ,transforms= None , unaligned = False):\n",
    "        self.traisnform = transforms.Compose(transforms_)\n",
    "\n",
    "        self.unaligned = unaligned\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "data_dir = \"/home/aman/code/CV/throat_infection/data\"\n",
    "classes = sorted(os.listdir(data_dir))\n",
    "\n",
    "class_to_label = {class_name: label for label ,class_name in enumerate(classes)}\n",
    "\n",
    "\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "\n",
    "    def __init__(self , data_dir , transforms=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transforms\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        for class_name , label in class_to_label.items():\n",
    "            class_dir = os.path.join(data_dir , class_name)\n",
    "\n",
    "            for image_path in os.listdir(class_dir):\n",
    "                self.image_paths.append(os.path.join(class_dir , image_path))\n",
    "                self.labels.append(label)\n",
    "        \n",
    "        random.shuffle(self.image_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self ,idx):\n",
    "        random.shuffle(self.image_paths)\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
